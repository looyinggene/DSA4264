{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e6d79f6-c280-4e7a-8dfc-70be97f2ef9b",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74132b43-efce-4fd9-8005-0ba2744a728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Retrieving api key\n",
    "load_dotenv(\"../key.env\")\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3dd46a-9738-4409-891e-cc2045eb0153",
   "metadata": {},
   "source": [
    "## Reading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a741050f-4cd2-419e-add9-14c83a721542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the get_bus_info function to make bus info related API calls\n",
    "%run get_bus_info_function.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a1aa4a-8440-4ecb-b624-bbff7043aeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_services_df = get_bus_info(\"https://datamall2.mytransport.sg/ltaodataservice/BusServices\", api_key)\n",
    "bus_routes_df = get_bus_info(\"https://datamall2.mytransport.sg/ltaodataservice/BusRoutes\", api_key)\n",
    "bus_stops_df = get_bus_info(\"https://datamall2.mytransport.sg/ltaodataservice/BusStops\", api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4bea12-7c2d-4a30-bd87-a23dc0d082aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stop_pv_jul = pd.read_csv(\"../datasets/pv_bus_stops/transport_node_bus_202407.csv\")\n",
    "bus_stop_pv_aug = pd.read_csv(\"../datasets/pv_bus_stops/transport_node_bus_202408.csv\")\n",
    "bus_stop_pv_sep = pd.read_csv(\"../datasets/pv_bus_stops/transport_node_bus_202409.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be341f6-a1ff-4338-a5c5-c81905108e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_od_jul = pd.read_csv(\"../datasets/pv_od_bus_stops/origin_destination_bus_202407.csv\")\n",
    "bus_od_aug = pd.read_csv(\"../datasets/pv_od_bus_stops/origin_destination_bus_202408.csv\")\n",
    "bus_od_sep = pd.read_csv(\"../datasets/pv_od_bus_stops/origin_destination_bus_202409.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a9a872-e0ed-4dbb-a4c0-075980996fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trunk_buses_df = bus_services_df[bus_services_df['Category'] == \"TRUNK\"]\n",
    "bus_routes_df = pd.merge(bus_routes_df, trunk_buses_df[['ServiceNo']], on='ServiceNo', how='inner')\n",
    "bus_routes_simple = bus_routes_df[[\"ServiceNo\", \"Direction\", \"StopSequence\", \"BusStopCode\"]]\n",
    "bus_stops_simple = bus_stops_df[[\"BusStopCode\", \"RoadName\", \"Description\"]]\n",
    "\n",
    "bus_routes_stops = pd.merge(bus_routes_simple, bus_stops_simple, on=\"BusStopCode\", how=\"inner\")\n",
    "bus_routes_stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899ec811-580f-407d-947a-cb06d1af690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_station_pv_jul = pd.read_csv(\"../datasets/pv_train_stations/transport_node_train_202407.csv\")\n",
    "train_station_pv_aug = pd.read_csv(\"../datasets/pv_train_stations/transport_node_train_202408.csv\")\n",
    "train_station_pv_sep = pd.read_csv(\"../datasets/pv_train_stations/transport_node_train_202409.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702840c-47ef-4d54-af83-7c2dab8bdd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_station_pv_jul['PT_CODE'] = train_station_pv_jul['PT_CODE'].str.split('/')\n",
    "train_station_jul = train_station_pv_jul.explode('PT_CODE').reset_index(drop=True)\n",
    "train_station_pv_aug['PT_CODE'] = train_station_pv_aug['PT_CODE'].str.split('/')\n",
    "train_station_aug = train_station_pv_aug.explode('PT_CODE').reset_index(drop=True)\n",
    "train_station_pv_sep['PT_CODE'] = train_station_pv_sep['PT_CODE'].str.split('/')\n",
    "train_station_sep = train_station_pv_sep.explode('PT_CODE').reset_index(drop=True)\n",
    "train_station_sep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6458cb-1e96-463d-8376-8c708e8675dc",
   "metadata": {},
   "source": [
    "## EDA of Bus Routes and Services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3324d06-bc26-4216-889a-b38693aa4b01",
   "metadata": {},
   "source": [
    "### 1a. Trend of Passenger Volume by Bus Route\n",
    "- Assumption: Passenger Volumes represented by Total Number of Tap Ins and Tap Outs\n",
    "- Things to note: There are multiple buses services at the same bus stops, the passenger volume is computed by total tap volumes of bus stops along the bus routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b823a0-3fc1-45c5-aa36-7380413b2575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'BusStopCode' and 'BusStop' to string\n",
    "bus_routes_stops['BusStopCode'] = bus_routes_stops['BusStopCode'].astype(str)\n",
    "bus_stop_pv_jul['PT_CODE'] = bus_stop_pv_jul['PT_CODE'].astype(str)\n",
    "bus_stop_pv_aug['PT_CODE'] = bus_stop_pv_aug['PT_CODE'].astype(str)\n",
    "bus_stop_pv_sep['PT_CODE'] = bus_stop_pv_sep['PT_CODE'].astype(str)\n",
    "\n",
    "# Merge bus_routes with bus_stops_passenger_volume to get passenger volumes per route\n",
    "route_passenger_volumes = pd.merge(bus_routes_stops, bus_stop_pv_jul, \n",
    "                                   left_on='BusStopCode', right_on=\"PT_CODE\", how='left')\n",
    "route_passenger_volumes_aug = pd.merge(bus_routes_stops, bus_stop_pv_aug, \n",
    "                                       left_on='BusStopCode', right_on=\"PT_CODE\", how='left')\n",
    "route_passenger_volumes_sep = pd.merge(bus_routes_stops, bus_stop_pv_sep, \n",
    "                                       left_on='BusStopCode', right_on=\"PT_CODE\", how='left')\n",
    "\n",
    "# Group by 'ServiceNo' and 'YEAR_MONTH' to get the total tap-in and tap-out volumes for each service in each month\n",
    "monthly_passenger_volume_jul = route_passenger_volumes.groupby(['ServiceNo', 'YEAR_MONTH'])[['TOTAL_TAP_IN_VOLUME', 'TOTAL_TAP_OUT_VOLUME']].sum().reset_index()\n",
    "monthly_passenger_volume_aug = route_passenger_volumes_aug.groupby(['ServiceNo', 'YEAR_MONTH'])[['TOTAL_TAP_IN_VOLUME', 'TOTAL_TAP_OUT_VOLUME']].sum().reset_index()\n",
    "monthly_passenger_volume_sep = route_passenger_volumes_sep.groupby(['ServiceNo', 'YEAR_MONTH'])[['TOTAL_TAP_IN_VOLUME', 'TOTAL_TAP_OUT_VOLUME']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75560ab7-a937-461b-b312-ffd7b8b761a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all three months' data\n",
    "all_months_data = pd.concat([monthly_passenger_volume_jul, \n",
    "                             monthly_passenger_volume_aug,\n",
    "                             monthly_passenger_volume_sep])\n",
    "\n",
    "# Reset index after concatenation\n",
    "all_months_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create a new column 'TOTAL_TAP_VOLUME'\n",
    "all_months_data['TOTAL_TAP_VOLUME'] = all_months_data['TOTAL_TAP_IN_VOLUME'] + all_months_data['TOTAL_TAP_OUT_VOLUME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7e8133-b7f9-46e3-b5e6-691b1355bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the data to have 'ServiceNo' as rows and 'YEAR_MONTH' as columns\n",
    "tap_in_pivot = all_months_data.pivot(index='ServiceNo', columns='YEAR_MONTH', values='TOTAL_TAP_VOLUME')\n",
    "\n",
    "# Preview the pivot table\n",
    "tap_in_pivot.head()\n",
    "\n",
    "# Assuming tap_in_pivot already has the data for '2024-07', '2024-08', and '2024-09'\n",
    "tap_in_pivot['Decreasing'] = (tap_in_pivot['2024-07'] > tap_in_pivot['2024-08']) & (tap_in_pivot['2024-08'] > tap_in_pivot['2024-09'])\n",
    "\n",
    "# Create a DataFrame for routes with decreasing tap-ins\n",
    "decreasing_routes_df = tap_in_pivot[tap_in_pivot['Decreasing']].reset_index()\n",
    "decreasing_routes_df.rename(columns={'YEAR_MONTH': 'Index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e4562e-ea0d-4689-b9b3-7cdde8a33aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the decrease from '2024-07' to '2024-09'\n",
    "decreasing_routes_df['Decrease'] = decreasing_routes_df['2024-07'] - decreasing_routes_df['2024-09']\n",
    "# Calculate the average from '2024-07' to '2024-09'\n",
    "decreasing_routes_df['Average'] = decreasing_routes_df[['2024-07', '2024-08', '2024-09']].mean(axis=1)\n",
    "\n",
    "\n",
    "# Sort the DataFrame by 'Decrease' in descending order\n",
    "decreasing_routes_df_sorted = decreasing_routes_df.sort_values(by='Decrease', ascending=False)\n",
    "decreasing_routes_df_sorted.to_csv('../datasets/pv_eda/routes_w_decreasing_pv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd09980c-a785-4505-8f67-ebde4b49fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top 10 routes with the largest decrease\n",
    "top_10_decreasing_routes = decreasing_routes_df_sorted.head(10)\n",
    "\n",
    "# Extract the tap-in data for the selected routes using .loc\n",
    "tap_in = tap_in_pivot.loc[top_10_decreasing_routes['ServiceNo'], ['2024-07', '2024-08', '2024-09']]\n",
    "\n",
    "# Reset index to make 'ServiceNo' a column\n",
    "tap_in.reset_index(inplace=True)\n",
    "\n",
    "# Plot the line graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plotting directly without iterating\n",
    "tap_in.set_index('ServiceNo').T.plot(marker='o', ax=plt.gca())\n",
    "\n",
    "plt.title('Top 10 Routes with Largest Decrease (2024-07 to 2024-09)')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Tap-In Volume')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Service Number', bbox_to_anchor=(1, 1), loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64788e95-95ce-42aa-84ee-518ff77a36ab",
   "metadata": {},
   "source": [
    "### 1b. Normalise Passenger Volumes of Bus Routes by Total Number of Bus Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a4d1ad-b9ee-489c-abc6-d547b1e24b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'bus_service_no' and count the total number of stops it serves 'stop_sequence' for each bus service\n",
    "route_stop_count = bus_routes_df.groupby('ServiceNo')['StopSequence'].count().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "route_stop_count.columns = ['ServiceNo', 'TotalStops']\n",
    "\n",
    "# Normalise the dataset\n",
    "normalised_bus_services_df = pd.merge(decreasing_routes_df, route_stop_count, \n",
    "                                   on = \"ServiceNo\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e372b23-e233-4b14-baf4-4896a8de2ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the relevant columns\n",
    "features = ['Decrease', 'Average', 'TotalStops']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "# Scale the features\n",
    "normalised_bus_services_df[features] = scaler.fit_transform(normalised_bus_services_df[features])\n",
    "\n",
    "# Initialize PCA to capture all three components\n",
    "pca = PCA(n_components=3)  # Number of components equals number of original features\n",
    "pca.fit(normalised_bus_services_df[features])\n",
    "\n",
    "# Transform the data to get principal components\n",
    "pca_components = pca.transform(normalised_bus_services_df[features])\n",
    "\n",
    "# Extract and display the component loadings\n",
    "loadings = pca.components_\n",
    "feature_names = features\n",
    "for i, component in enumerate(loadings):\n",
    "    print(f\"Principal Component {i+1}:\")\n",
    "    for feature, loading in zip(feature_names, component):\n",
    "        print(f\"   {feature}: {loading:.2f}\")\n",
    "\n",
    "# Variance explained by each principal component\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "for i, variance in enumerate(explained_variance):\n",
    "    print(f\"Principal Component {i+1} explains {variance:.2%} of the variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c882d9a-493c-437b-a9b9-4be062ffb619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weights by normalizing component loadings\n",
    "total_loading = abs(0.58) + abs(0.60) + abs(0.55)\n",
    "weights = {\n",
    "    'Decrease': abs(0.58) / total_loading,\n",
    "    'Average': abs(0.60) / total_loading,\n",
    "    'TotalStops': abs(0.55) / total_loading\n",
    "}\n",
    "\n",
    "# Calculate Normalised score as a weighted sum\n",
    "normalised_bus_services_df['Normalised'] = (\n",
    "    weights['Decrease'] * normalised_bus_services_df['Decrease'] +\n",
    "    weights['Average'] * normalised_bus_services_df['Average'] +\n",
    "    weights['TotalStops'] * normalised_bus_services_df['TotalStops']\n",
    ")\n",
    "\n",
    "\n",
    "bus_routes_pv_softmax = normalised_bus_services_df.copy()\n",
    "\n",
    "# Min-max scale Normalised column to range between 0 and 10\n",
    "scaler = MinMaxScaler(feature_range=(0, 10))\n",
    "bus_routes_pv_softmax['Scaled_Normalised'] = scaler.fit_transform(bus_routes_pv_softmax[['Normalised']])\n",
    "\n",
    "# Apply softmax on the scaled values\n",
    "max_scaled = bus_routes_pv_softmax['Scaled_Normalised'].max()\n",
    "bus_routes_pv_softmax['Softmax'] = np.exp(bus_routes_pv_softmax['Scaled_Normalised'] - max_scaled) / np.sum(np.exp(bus_routes_pv_softmax['Scaled_Normalised'] - max_scaled))\n",
    "\n",
    "# Sort the DataFrame by 'Normalised' in descending order\n",
    "decreasing_normalised_bus_services_df_sorted = bus_routes_pv_softmax.sort_values(by='Softmax', ascending=False)\n",
    "decreasing_normalised_bus_services_df_sorted.to_csv('../datasets/pv_eda/routes_w_normalised_pv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d9f37e-5c3e-4da8-aca7-8d4ab96677e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top 10 routes with the largest decrease\n",
    "top_10_decreasing_routes = decreasing_normalised_bus_services_df_sorted.head(10)\n",
    "\n",
    "# Extract the tap-in data for the selected routes using .loc\n",
    "tap_in = tap_in_pivot.loc[top_10_decreasing_routes['ServiceNo'], ['2024-07', '2024-08', '2024-09']]\n",
    "\n",
    "# Reset index to make 'ServiceNo' a column\n",
    "tap_in.reset_index(inplace=True)\n",
    "\n",
    "# Plot the line graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plotting directly without iterating\n",
    "tap_in.set_index('ServiceNo').T.plot(marker='o', ax=plt.gca())\n",
    "\n",
    "plt.title('Top 10 Routes with Significant Decrease (2024-07 to 2024-09)')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Tap Volume')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Service Number', bbox_to_anchor=(1, 1), loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4c5c02-06b7-40f2-8e0e-75cf5c0eee34",
   "metadata": {},
   "source": [
    "### 2a. Trend of Passenger Volumes by Bus Stops\n",
    "- Assumption: Passenger Volumes represented by Total Number of Tap Ins and Tap Outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9a3731-83c0-4be0-beb9-47dd414e22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'TOTAL_TAP_VOLUME' summing tap-in and tap-out volumes\n",
    "bus_stop_pv_jul['TOTAL_TAP_VOLUME'] = bus_stop_pv_jul['TOTAL_TAP_IN_VOLUME'] + bus_stop_pv_jul['TOTAL_TAP_OUT_VOLUME']\n",
    "bus_stop_pv_aug['TOTAL_TAP_VOLUME'] = bus_stop_pv_aug['TOTAL_TAP_IN_VOLUME'] + bus_stop_pv_aug['TOTAL_TAP_OUT_VOLUME']\n",
    "bus_stop_pv_sep['TOTAL_TAP_VOLUME'] = bus_stop_pv_sep['TOTAL_TAP_IN_VOLUME'] + bus_stop_pv_sep['TOTAL_TAP_OUT_VOLUME']\n",
    "\n",
    "# Group by PT_CODE and YEAR_MONTH to get total taps for each bus stop per month\n",
    "monthly_tap_jul = bus_stop_pv_jul.groupby(['PT_CODE', 'YEAR_MONTH'])[['TOTAL_TAP_VOLUME']].sum().reset_index()\n",
    "monthly_tap_aug = bus_stop_pv_aug.groupby(['PT_CODE', 'YEAR_MONTH'])[['TOTAL_TAP_VOLUME']].sum().reset_index()\n",
    "monthly_tap_sep = bus_stop_pv_sep.groupby(['PT_CODE', 'YEAR_MONTH'])[['TOTAL_TAP_VOLUME']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cb879f-1801-4b5d-8270-bd4d23c0a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all three months' data\n",
    "all_months_taps = pd.concat([monthly_tap_jul, \n",
    "                             monthly_tap_aug,\n",
    "                             monthly_tap_sep])\n",
    "\n",
    "# Reset index after concatenation\n",
    "all_months_taps.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ddd1b4-86a5-48e4-9ab9-31372f1c39f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'PT_CODE' and 'BusStopCode' are of the same data type\n",
    "all_months_taps['PT_CODE'] = all_months_taps['PT_CODE'].astype(str)\n",
    "\n",
    "# Pivot the data to have 'ServiceNo' as rows and 'YEAR_MONTH' as columns\n",
    "tap_bus_stop_pivot = all_months_taps.pivot(index='PT_CODE', columns='YEAR_MONTH', values='TOTAL_TAP_VOLUME')\n",
    "\n",
    "# Preview the pivot table\n",
    "tap_bus_stop_pivot.head()\n",
    "\n",
    "# Assuming tap_in_pivot already has the data for '2024-07', '2024-08', and '2024-09'\n",
    "tap_bus_stop_pivot['Decreasing'] = (tap_bus_stop_pivot['2024-07'] > tap_bus_stop_pivot['2024-08']) & (tap_bus_stop_pivot['2024-08'] > tap_bus_stop_pivot['2024-09'])\n",
    "\n",
    "# Create a DataFrame for routes with decreasing tap-ins\n",
    "taps_bus_stop_df = tap_bus_stop_pivot[tap_bus_stop_pivot['Decreasing']].reset_index()\n",
    "taps_bus_stop_df.rename(columns={'YEAR_MONTH': 'Index'}, inplace=True)\n",
    "\n",
    "# Ensure that 'bus_routes_stops_cleaned' has unique 'BusStopCode'\n",
    "bus_routes_stops_cleaned = bus_routes_stops.drop_duplicates(subset=['BusStopCode'])\n",
    "\n",
    "# Merge to get the name and description for both the ORIGIN and DESTINATION in July\n",
    "decreasing_bus_stops_df = pd.merge(\n",
    "    taps_bus_stop_df, \n",
    "    bus_routes_stops_cleaned[['BusStopCode', 'RoadName', 'Description']],\n",
    "    left_on='PT_CODE', \n",
    "    right_on='BusStopCode', \n",
    "    how='left'\n",
    ").drop(columns=['BusStopCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65335f23-ed7a-465c-a974-bc2239400c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the decrease from '2024-07' to '2024-09'\n",
    "decreasing_bus_stops_df['Decrease'] = decreasing_bus_stops_df['2024-07'] - decreasing_bus_stops_df['2024-09']\n",
    "\n",
    "# Sort the DataFrame by 'Decrease' in descending order\n",
    "decreasing_bus_stops_df_sorted = decreasing_bus_stops_df.sort_values(by='Decrease', ascending=False)\n",
    "decreasing_bus_stops_df_sorted.to_csv('../datasets/pv_eda/bus_stops_w_decreasing_pv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c757cb-9b95-4826-b1a2-2e7bdd939aed",
   "metadata": {},
   "source": [
    "### 2b. Normalise Passenger Volumes of Bus Stops by Unique Number of Bus Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e12dc9-86ed-4931-918f-7910782de8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'bus_stop_code' and count the unique 'bus_service' for each stop\n",
    "bus_service_count = bus_routes_df.groupby('BusStopCode')['ServiceNo'].nunique().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "bus_service_count.columns = ['BusStopCode', 'TotalBusService']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0324bc6-8244-4b73-a008-2356b6e09e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the dataset\n",
    "normalised_bus_stops_df = pd.merge(decreasing_bus_stops_df, bus_service_count, \n",
    "                                   left_on = \"PT_CODE\", right_on = \"BusStopCode\",\n",
    "                                   how = \"left\").drop(columns=['BusStopCode'])\n",
    "normalised_bus_stops_df['Normalised'] = normalised_bus_stops_df['Decrease'] / normalised_bus_stops_df['TotalBusService']\n",
    "\n",
    "# Sort the DataFrame by 'Normalised' in descending order\n",
    "decreasing_normalised_bus_stops_df_sorted = normalised_bus_stops_df.sort_values(by='Normalised', ascending=False)\n",
    "decreasing_normalised_bus_stops_df_sorted.to_csv('../datasets/pv_eda/bus_stops_w_normalised_pv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6ffc1a-cdbc-4e33-bfa9-8a80b8300069",
   "metadata": {},
   "source": [
    "### 3. Average (Mean and Median) Monthly Bus Servicing the Same Origin and Destination Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71507f3-9cb0-423b-ab79-968267e09176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert both 'ORIGIN_PT_CODE' and 'DESTINATION_PT_CODE' columns to string for July\n",
    "bus_od_jul[['ORIGIN_PT_CODE', 'DESTINATION_PT_CODE']] = bus_od_jul[['ORIGIN_PT_CODE', 'DESTINATION_PT_CODE']].astype(str)\n",
    "bus_od_aug[['ORIGIN_PT_CODE', 'DESTINATION_PT_CODE']] = bus_od_aug[['ORIGIN_PT_CODE', 'DESTINATION_PT_CODE']].astype(str)\n",
    "bus_od_sep[['ORIGIN_PT_CODE', 'DESTINATION_PT_CODE']] = bus_od_sep[['ORIGIN_PT_CODE', 'DESTINATION_PT_CODE']].astype(str)\n",
    "\n",
    "# Group by 'YEAR_MONTH', 'ORIGIN_PT_CODE' and 'DESTINATION_PT_CODE'\n",
    "grouped_trips_jul = bus_od_jul.groupby(['YEAR_MONTH', 'ORIGIN_PT_CODE', 'DESTINATION_PT_CODE'])[['TOTAL_TRIPS']].sum().reset_index()\n",
    "grouped_trips_aug = bus_od_aug.groupby(['YEAR_MONTH', 'ORIGIN_PT_CODE', 'DESTINATION_PT_CODE'])[['TOTAL_TRIPS']].sum().reset_index()\n",
    "grouped_trips_sep = bus_od_sep.groupby(['YEAR_MONTH', 'ORIGIN_PT_CODE', 'DESTINATION_PT_CODE'])[['TOTAL_TRIPS']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8eb9c2-d969-45a4-b732-624974c51f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that 'bus_routes_stops_cleaned' has unique 'BusStopCode'\n",
    "bus_routes_stops_cleaned = bus_routes_stops.drop_duplicates(subset=['BusStopCode'])\n",
    "\n",
    "# Merge to get the name and description for both the ORIGIN and DESTINATION in July\n",
    "route_trips_jul = pd.merge(\n",
    "    grouped_trips_jul, \n",
    "    bus_routes_stops_cleaned[['BusStopCode', 'Description']].rename(columns={'Description': 'ORIGIN_DESCRIPTION'}),\n",
    "    left_on='ORIGIN_PT_CODE', \n",
    "    right_on='BusStopCode', \n",
    "    how='left'\n",
    ").drop(columns=['BusStopCode'])\n",
    "\n",
    "route_trips_jul = pd.merge(\n",
    "    route_trips_jul, \n",
    "    bus_routes_stops_cleaned[['BusStopCode', 'Description']].rename(columns={'Description': 'DESTINATION_DESCRIPTION'}),\n",
    "    left_on='DESTINATION_PT_CODE', \n",
    "    right_on='BusStopCode', \n",
    "    how='left'\n",
    ").drop(columns=['BusStopCode'])\n",
    "\n",
    "# Merge to get the name and description for both the ORIGIN and DESTINATION in July\n",
    "route_trips_aug = pd.merge(\n",
    "    grouped_trips_aug, \n",
    "    bus_routes_stops_cleaned[['BusStopCode', 'Description']].rename(columns={'Description': 'ORIGIN_DESCRIPTION'}),\n",
    "    left_on='ORIGIN_PT_CODE', \n",
    "    right_on='BusStopCode', \n",
    "    how='left'\n",
    ").drop(columns=['BusStopCode'])\n",
    "\n",
    "route_trips_aug = pd.merge(\n",
    "    route_trips_aug, \n",
    "    bus_routes_stops_cleaned[['BusStopCode', 'Description']].rename(columns={'Description': 'DESTINATION_DESCRIPTION'}),\n",
    "    left_on='DESTINATION_PT_CODE', \n",
    "    right_on='BusStopCode', \n",
    "    how='left'\n",
    ").drop(columns=['BusStopCode'])\n",
    "\n",
    "# Merge to get the name and description for both the ORIGIN and DESTINATION in July\n",
    "route_trips_sep = pd.merge(\n",
    "    grouped_trips_sep, \n",
    "    bus_routes_stops_cleaned[['BusStopCode', 'Description']].rename(columns={'Description': 'ORIGIN_DESCRIPTION'}),\n",
    "    left_on='ORIGIN_PT_CODE', \n",
    "    right_on='BusStopCode', \n",
    "    how='left'\n",
    ").drop(columns=['BusStopCode'])\n",
    "\n",
    "route_trips_sep = pd.merge(\n",
    "    route_trips_sep, \n",
    "    bus_routes_stops_cleaned[['BusStopCode', 'Description']].rename(columns={'Description': 'DESTINATION_DESCRIPTION'}),\n",
    "    left_on='DESTINATION_PT_CODE', \n",
    "    right_on='BusStopCode', \n",
    "    how='left'\n",
    ").drop(columns=['BusStopCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fa2fd6-85db-4ad8-b5d8-79ee79937b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all three months' data\n",
    "all_months_trips = pd.concat([route_trips_jul, \n",
    "                             route_trips_aug,\n",
    "                             route_trips_sep])\n",
    "\n",
    "# Reset index after concatenation\n",
    "all_months_trips.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18e35bb-2c42-4a6b-93f3-0025cb624663",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_mean_total_trips = all_months_trips.groupby(['ORIGIN_PT_CODE', \n",
    "                                                'DESTINATION_PT_CODE', \n",
    "                                                'ORIGIN_DESCRIPTION', \n",
    "                                                'DESTINATION_DESCRIPTION'])[['TOTAL_TRIPS']].mean().reset_index()\n",
    "\n",
    "# Sort the DataFrame by 'TOTAL_TRIPS' in descending order\n",
    "mean_trips_sorted = monthly_mean_total_trips.sort_values(by='TOTAL_TRIPS', ascending=False)\n",
    "mean_trips_sorted.to_csv('../datasets/pv_eda/mean_trips.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3381b5a1-de51-465d-ba80-80667fbd8b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_median_total_trips = all_months_trips.groupby(['ORIGIN_PT_CODE', \n",
    "                                                'DESTINATION_PT_CODE', \n",
    "                                                'ORIGIN_DESCRIPTION', \n",
    "                                                'DESTINATION_DESCRIPTION'])[['TOTAL_TRIPS']].median().reset_index()\n",
    "\n",
    "# Sort the DataFrame by 'TOTAL_TRIPS' in descending order\n",
    "median_trips_sorted = monthly_median_total_trips.sort_values(by='TOTAL_TRIPS', ascending=False)\n",
    "median_trips_sorted.to_csv('../datasets/pv_eda/median_trips.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f20fa7-acd9-42f3-b894-db389386a0f8",
   "metadata": {},
   "source": [
    "## Summary\n",
    "1. Bus stops and services that saw a significant decrease are those that serve higher educational institutions (e.g. Polytechnics, ITEs) -- July to September coincide with term breaks\n",
    "2. Top bus services based on their monthly number of trips are those that serve short distances "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911864d4-b778-4838-b2d8-fa3dd099e862",
   "metadata": {},
   "source": [
    "## EDA of Bus Routes and Services along Interchanges and Stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd95c42-0f0b-47f8-a063-92e3bd2f4044",
   "metadata": {},
   "source": [
    "### 4. Total Number of Interchanges and Stations each Bus Service serves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb467d6f-ed49-4fc5-bb7b-e762c2843ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_bus_stops = bus_stops_df[bus_stops_df['Description'].str.contains(r'\\b(Int|Stn)(\\b|[\\s/])', case=False, na=False)]\n",
    "filtered_bus_stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290462a5-f8d7-4cce-8fa0-5bbc65c9168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the filtered bus stops with the bus routes dataframe\n",
    "merged_df = pd.merge(bus_routes_df, filtered_bus_stops, on='BusStopCode', how='inner')\n",
    "\n",
    "# Group by the service number and count the bus stops\n",
    "bus_service_stop_counts = merged_df.groupby('ServiceNo')['BusStopCode'].nunique().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "bus_service_stop_counts.columns = ['ServiceNo', 'CountOfStopsWithIntOrStn']\n",
    "\n",
    "# Sort the DataFrame by 'CountOfStopsWithIntOrStn' in descending order\n",
    "int_stn_bus_service_sorted = bus_service_stop_counts.sort_values(by='CountOfStopsWithIntOrStn', ascending=False)\n",
    "int_stn_bus_service_sorted.to_csv('../datasets/pv_eda/int_stn_bus_service.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34915966-49e8-4d3e-a97b-341b0a389bfd",
   "metadata": {},
   "source": [
    "### 5a. Trend of Passenger Volume at Interchanges and Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b067b68b-b73c-4085-adcf-3f3396946b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_stn_pv_sorted = decreasing_bus_stops_df_sorted[decreasing_bus_stops_df_sorted['Description'].str.contains(r'\\b(Int|Stn)(\\b|[\\s/])', case=False, na=False)]\n",
    "int_stn_pv_sorted.to_csv('../datasets/pv_eda/int_stn_pv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f563275a-a5b1-418a-a71e-488fcb04f837",
   "metadata": {},
   "source": [
    "### 5b. Normalise Passenger Volume at Interchanges and Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8a32ee-745d-4291-ae75-47979b103227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_stn_pv_normalise_sorted = decreasing_normalised_bus_stops_df_sorted[decreasing_normalised_bus_stops_df_sorted['Description'].str.contains(r'Int|Stn', case=False, na=False)]\n",
    "int_stn_pv_normalise_sorted = decreasing_normalised_bus_stops_df_sorted[\n",
    "    decreasing_normalised_bus_stops_df_sorted['Description'].str.contains(\n",
    "        r'\\b(Int|Stn)(\\b|[\\s/])', case=False, na=False\n",
    "    )\n",
    "]\n",
    "\n",
    "int_stn_pv_softmax = int_stn_pv_normalise_sorted.copy()\n",
    "\n",
    "# Min-max scale Normalised column to range between 0 and 10\n",
    "scaler = MinMaxScaler(feature_range=(0, 10))\n",
    "int_stn_pv_softmax['Scaled_Normalised'] = scaler.fit_transform(int_stn_pv_softmax[['Normalised']])\n",
    "\n",
    "# Apply softmax on the scaled values\n",
    "max_scaled = int_stn_pv_softmax['Scaled_Normalised'].max()\n",
    "int_stn_pv_softmax['Softmax'] = np.exp(int_stn_pv_softmax['Scaled_Normalised'] - max_scaled) / np.sum(np.exp(int_stn_pv_softmax['Scaled_Normalised'] - max_scaled))\n",
    "\n",
    "int_stn_pv_softmax.to_csv('../datasets/pv_eda/int_stn_normalised_pv.csv', index=False)\n",
    "int_stn_pv_softmax[['PT_CODE', 'Normalised', 'Scaled_Normalised', 'Softmax']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c4958f-3160-48bd-8c53-9aff18adc5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles_to_test = [0.7, 0.8, 0.85, 0.9]\n",
    "results = {}\n",
    "\n",
    "for p in percentiles_to_test:\n",
    "    threshold_value = int_stn_pv_softmax['Softmax'].quantile(p)\n",
    "    filtered_threshold = int_stn_pv_softmax[int_stn_pv_softmax['Softmax'] > threshold_value]\n",
    "    results[p] = len(filtered_threshold)  # or any other metric of interest\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(list(results.items()), columns=['Percentile', 'Count'])\n",
    "print(results_df)\n",
    "\n",
    "plt.bar(results_df['Percentile'].astype(str), results_df['Count'])\n",
    "plt.xlabel('Percentile Threshold')\n",
    "plt.ylabel('Number of Routes Filtered')\n",
    "plt.title('Impact of Different Percentile Thresholds on Route Filtering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02943de-407b-427b-9e23-42257b72fa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold at the 80th percentile of the Softmax values\n",
    "threshold_value = int_stn_pv_softmax['Softmax'].quantile(0.8)\n",
    "\n",
    "# Filter for routes with Softmax values above this threshold\n",
    "filtered_threshold = int_stn_pv_softmax[int_stn_pv_softmax['Softmax'] > threshold_value]\n",
    "filtered_threshold = filtered_threshold['PT_CODE']\n",
    "\n",
    "# Merge the filtered bus stops with the bus routes dataframe\n",
    "merged_threshold_df = pd.merge(bus_routes_df, filtered_threshold, \n",
    "                               left_on='BusStopCode', right_on='PT_CODE', \n",
    "                               how='inner').drop(columns=['PT_CODE'])\n",
    "\n",
    "# Group by the service number and count the bus stops\n",
    "threshold_stop_counts = merged_threshold_df.groupby('ServiceNo')['BusStopCode'].nunique().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "threshold_stop_counts.columns = ['ServiceNo', 'IntStnLargeDecrease']\n",
    "\n",
    "# Sort the DataFrame by 'IntStnLargeDecrease' in descending order\n",
    "threshold_bus_service_sorted = threshold_stop_counts.sort_values(by='IntStnLargeDecrease', ascending=False)\n",
    "threshold_bus_service_sorted.to_csv('../datasets/pv_eda/threshold_int_stn_bus.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e861e710-5c1b-493c-a3a1-1e054e3c1b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select services that serve at least 3 stations or interchanges with a large decrease\n",
    "more_than_3_stops = threshold_bus_service_sorted[threshold_bus_service_sorted['IntStnLargeDecrease'] > 3]\n",
    "\n",
    "# Plot graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(more_than_3_stops['ServiceNo'], \n",
    "         more_than_3_stops['IntStnLargeDecrease'], \n",
    "         color='purple')\n",
    "plt.xlabel('Count of Stops with Large Decrease in Passenger Volume')\n",
    "plt.ylabel('Bus Service Number')\n",
    "plt.title('Count of Bus Stops with Large Decrease in Passenger Volume by Bus Service')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a80421-82cd-4cc6-b733-e0952e9c8aab",
   "metadata": {},
   "source": [
    "## EDA of Train Routes and Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa74e03d-419a-411f-a358-e87eebfcdb25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d52b5fd",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dedc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Retrieving api key\n",
    "load_dotenv(\"../key.env\")\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d50fe",
   "metadata": {},
   "source": [
    "## Reading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea651377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the get_bus_info function to make bus info related API calls\n",
    "%run get_bus_info_function.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea4d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_services_df = get_bus_info(\"https://datamall2.mytransport.sg/ltaodataservice/BusServices\", api_key)\n",
    "bus_routes_df = get_bus_info(\"https://datamall2.mytransport.sg/ltaodataservice/BusRoutes\", api_key)\n",
    "bus_stops_df = get_bus_info(\"https://datamall2.mytransport.sg/ltaodataservice/BusStops\", api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7d1ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stop_pv_jul = pd.read_csv(\"../datasets/pv_bus_stops/transport_node_bus_202407.csv\")\n",
    "bus_stop_pv_aug = pd.read_csv(\"../datasets/pv_bus_stops/transport_node_bus_202408.csv\")\n",
    "bus_stop_pv_sep = pd.read_csv(\"../datasets/pv_bus_stops/transport_node_bus_202409.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6347cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_od_jul = pd.read_csv(\"../datasets/pv_od_bus_stops/origin_destination_bus_202407.csv\")\n",
    "bus_od_aug = pd.read_csv(\"../datasets/pv_od_bus_stops/origin_destination_bus_202408.csv\")\n",
    "bus_od_sep = pd.read_csv(\"../datasets/pv_od_bus_stops/origin_destination_bus_202409.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b061ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trunk_buses_df = bus_services_df[bus_services_df['Category'] == \"TRUNK\"]\n",
    "bus_routes_df = pd.merge(bus_routes_df, trunk_buses_df[['ServiceNo']], on='ServiceNo', how='inner')\n",
    "bus_routes_simple = bus_routes_df[[\"ServiceNo\", \"Direction\", \"StopSequence\", \"BusStopCode\"]]\n",
    "bus_stops_simple = bus_stops_df[[\"BusStopCode\", \"RoadName\", \"Description\"]]\n",
    "\n",
    "bus_routes_stops = pd.merge(bus_routes_simple, bus_stops_simple, on=\"BusStopCode\", how=\"inner\")\n",
    "bus_routes_stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a14d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_station_pv_jul = pd.read_csv(\"../datasets/pv_train_stations/transport_node_train_202407.csv\")\n",
    "train_station_pv_aug = pd.read_csv(\"../datasets/pv_train_stations/transport_node_train_202408.csv\")\n",
    "train_station_pv_sep = pd.read_csv(\"../datasets/pv_train_stations/transport_node_train_202409.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c997cc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_station_pv_jul['PT_CODE'] = train_station_pv_jul['PT_CODE'].str.split('/')\n",
    "train_station_jul = train_station_pv_jul.explode('PT_CODE').reset_index(drop=True)\n",
    "train_station_pv_aug['PT_CODE'] = train_station_pv_aug['PT_CODE'].str.split('/')\n",
    "train_station_aug = train_station_pv_aug.explode('PT_CODE').reset_index(drop=True)\n",
    "train_station_pv_sep['PT_CODE'] = train_station_pv_sep['PT_CODE'].str.split('/')\n",
    "train_station_sep = train_station_pv_sep.explode('PT_CODE').reset_index(drop=True)\n",
    "train_station_sep.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515744d2",
   "metadata": {},
   "source": [
    "## EDA of Bus Routes and Services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d5907e",
   "metadata": {},
   "source": [
    "### 1a. Trend of Passenger Volume by Bus Route\n",
    "- Assumption: Passenger Volumes represented by Total Number of Tap Ins and Tap Outs\n",
    "- Things to note: There are multiple buses services at the same bus stops, the passenger volume is computed by total tap volumes of bus stops along the bus routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20353b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'BusStopCode' and 'BusStop' to string\n",
    "bus_routes_stops['BusStopCode'] = bus_routes_stops['BusStopCode'].astype(str)\n",
    "bus_stop_pv_jul['PT_CODE'] = bus_stop_pv_jul['PT_CODE'].astype(str)\n",
    "bus_stop_pv_aug['PT_CODE'] = bus_stop_pv_aug['PT_CODE'].astype(str)\n",
    "bus_stop_pv_sep['PT_CODE'] = bus_stop_pv_sep['PT_CODE'].astype(str)\n",
    "\n",
    "# Merge bus_routes with bus_stops_passenger_volume to get passenger volumes per route\n",
    "route_passenger_volumes = pd.merge(bus_routes_stops, bus_stop_pv_jul, \n",
    "                                   left_on='BusStopCode', right_on=\"PT_CODE\", how='left')\n",
    "route_passenger_volumes_aug = pd.merge(bus_routes_stops, bus_stop_pv_aug, \n",
    "                                       left_on='BusStopCode', right_on=\"PT_CODE\", how='left')\n",
    "route_passenger_volumes_sep = pd.merge(bus_routes_stops, bus_stop_pv_sep, \n",
    "                                       left_on='BusStopCode', right_on=\"PT_CODE\", how='left')\n",
    "\n",
    "# Group by 'ServiceNo' and 'YEAR_MONTH' to get the total tap-in and tap-out volumes for each service in each month\n",
    "monthly_passenger_volume_jul = route_passenger_volumes.groupby(['ServiceNo', 'YEAR_MONTH'])[['TOTAL_TAP_IN_VOLUME', 'TOTAL_TAP_OUT_VOLUME']].sum().reset_index()\n",
    "monthly_passenger_volume_aug = route_passenger_volumes_aug.groupby(['ServiceNo', 'YEAR_MONTH'])[['TOTAL_TAP_IN_VOLUME', 'TOTAL_TAP_OUT_VOLUME']].sum().reset_index()\n",
    "monthly_passenger_volume_sep = route_passenger_volumes_sep.groupby(['ServiceNo', 'YEAR_MONTH'])[['TOTAL_TAP_IN_VOLUME', 'TOTAL_TAP_OUT_VOLUME']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f9edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all three months' data\n",
    "all_months_data = pd.concat([monthly_passenger_volume_jul, \n",
    "                             monthly_passenger_volume_aug,\n",
    "                             monthly_passenger_volume_sep])\n",
    "\n",
    "# Reset index after concatenation\n",
    "all_months_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create a new column 'TOTAL_TAP_VOLUME'\n",
    "all_months_data['TOTAL_TAP_VOLUME'] = all_months_data['TOTAL_TAP_IN_VOLUME'] + all_months_data['TOTAL_TAP_OUT_VOLUME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630f7008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the data to have 'ServiceNo' as rows and 'YEAR_MONTH' as columns\n",
    "tap_in_pivot = all_months_data.pivot(index='ServiceNo', columns='YEAR_MONTH', values='TOTAL_TAP_VOLUME')\n",
    "\n",
    "# Preview the pivot table\n",
    "tap_in_pivot.head()\n",
    "\n",
    "# Assuming tap_in_pivot already has the data for '2024-07', '2024-08', and '2024-09'\n",
    "tap_in_pivot['Decreasing'] = (tap_in_pivot['2024-07'] > tap_in_pivot['2024-08']) & (tap_in_pivot['2024-08'] > tap_in_pivot['2024-09'])\n",
    "\n",
    "# Create a DataFrame for routes with decreasing tap-ins\n",
    "decreasing_routes_df = tap_in_pivot[tap_in_pivot['Decreasing']].reset_index()\n",
    "decreasing_routes_df.rename(columns={'YEAR_MONTH': 'Index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3a5b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the decrease from '2024-07' to '2024-09'\n",
    "decreasing_routes_df['Decrease'] = decreasing_routes_df['2024-07'] - decreasing_routes_df['2024-09']\n",
    "# Calculate the average from '2024-07' to '2024-09'\n",
    "decreasing_routes_df['Average'] = decreasing_routes_df[['2024-07', '2024-08', '2024-09']].mean(axis=1)\n",
    "\n",
    "\n",
    "# Sort the DataFrame by 'Decrease' in descending order\n",
    "decreasing_routes_df_sorted = decreasing_routes_df.sort_values(by='Decrease', ascending=False)\n",
    "decreasing_routes_df_sorted.to_csv('../datasets/pv_eda/routes_w_decreasing_pv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1565c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top 10 routes with the largest decrease\n",
    "top_10_decreasing_routes = decreasing_routes_df_sorted.head(10)\n",
    "\n",
    "# Extract the tap-in data for the selected routes using .loc\n",
    "tap_in = tap_in_pivot.loc[top_10_decreasing_routes['ServiceNo'], ['2024-07', '2024-08', '2024-09']]\n",
    "\n",
    "# Reset index to make 'ServiceNo' a column\n",
    "tap_in.reset_index(inplace=True)\n",
    "\n",
    "# Plot the line graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plotting directly without iterating\n",
    "tap_in.set_index('ServiceNo').T.plot(marker='o', ax=plt.gca())\n",
    "\n",
    "plt.title('Top 10 Routes with Largest Decrease (2024-07 to 2024-09)')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Tap-In Volume')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Service Number', bbox_to_anchor=(1, 1), loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516b1494",
   "metadata": {},
   "source": [
    "### 1b. Normalise Passenger Volumes of Bus Routes by Total Number of Bus Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ef8420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'bus_service_no' and count the total number of stops it serves 'stop_sequence' for each bus service\n",
    "route_stop_count = bus_routes_df.groupby('ServiceNo')['StopSequence'].count().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "route_stop_count.columns = ['ServiceNo', 'TotalStops']\n",
    "\n",
    "# Normalise the dataset\n",
    "normalised_bus_services_df = pd.merge(decreasing_routes_df, route_stop_count, \n",
    "                                   on = \"ServiceNo\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834a8451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the relevant columns\n",
    "features = ['Decrease', 'Average', 'TotalStops']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "# Scale the features\n",
    "normalised_bus_services_df[features] = scaler.fit_transform(normalised_bus_services_df[features])\n",
    "\n",
    "# Initialize PCA to capture all three components\n",
    "pca = PCA(n_components=3)  # Number of components equals number of original features\n",
    "pca.fit(normalised_bus_services_df[features])\n",
    "\n",
    "# Transform the data to get principal components\n",
    "pca_components = pca.transform(normalised_bus_services_df[features])\n",
    "\n",
    "# Extract and display the component loadings\n",
    "loadings = pca.components_\n",
    "feature_names = features\n",
    "for i, component in enumerate(loadings):\n",
    "    print(f\"Principal Component {i+1}:\")\n",
    "    for feature, loading in zip(feature_names, component):\n",
    "        print(f\"   {feature}: {loading:.2f}\")\n",
    "\n",
    "# Variance explained by each principal component\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "for i, variance in enumerate(explained_variance):\n",
    "    print(f\"Principal Component {i+1} explains {variance:.2%} of the variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c22b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weights by normalizing component loadings\n",
    "total_loading = abs(0.58) + abs(0.60) + abs(0.55)\n",
    "weights = {\n",
    "    'Decrease': abs(0.58) / total_loading,\n",
    "    'Average': abs(0.60) / total_loading,\n",
    "    'TotalStops': abs(0.55) / total_loading\n",
    "}\n",
    "\n",
    "# Calculate Normalised score as a weighted sum\n",
    "normalised_bus_services_df['Normalised'] = (\n",
    "    weights['Decrease'] * normalised_bus_services_df['Decrease'] +\n",
    "    weights['Average'] * normalised_bus_services_df['Average'] +\n",
    "    weights['TotalStops'] * normalised_bus_services_df['TotalStops']\n",
    ")\n",
    "\n",
    "\n",
    "bus_routes_pv_softmax = normalised_bus_services_df.copy()\n",
    "\n",
    "# Min-max scale Normalised column to range between 0 and 10\n",
    "scaler = MinMaxScaler(feature_range=(0, 10))\n",
    "bus_routes_pv_softmax['Scaled_Normalised'] = scaler.fit_transform(bus_routes_pv_softmax[['Normalised']])\n",
    "\n",
    "# Apply softmax on the scaled values\n",
    "max_scaled = bus_routes_pv_softmax['Scaled_Normalised'].max()\n",
    "bus_routes_pv_softmax['Softmax'] = np.exp(bus_routes_pv_softmax['Scaled_Normalised'] - max_scaled) / np.sum(np.exp(bus_routes_pv_softmax['Scaled_Normalised'] - max_scaled))\n",
    "\n",
    "# Sort the DataFrame by 'Normalised' in descending order\n",
    "decreasing_normalised_bus_services_df_sorted = bus_routes_pv_softmax.sort_values(by='Softmax', ascending=False)\n",
    "decreasing_normalised_bus_services_df_sorted.to_csv('../datasets/pv_eda/routes_w_normalised_pv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadb51e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top 10 routes with the largest decrease\n",
    "top_10_decreasing_routes = decreasing_normalised_bus_services_df_sorted.head(10)\n",
    "\n",
    "# Extract the tap-in data for the selected routes using .loc\n",
    "tap_in = tap_in_pivot.loc[top_10_decreasing_routes['ServiceNo'], ['2024-07', '2024-08', '2024-09']]\n",
    "\n",
    "# Reset index to make 'ServiceNo' a column\n",
    "tap_in.reset_index(inplace=True)\n",
    "\n",
    "# Plot the line graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plotting directly without iterating\n",
    "tap_in.set_index('ServiceNo').T.plot(marker='o', ax=plt.gca())\n",
    "\n",
    "plt.title('Top 10 Routes with Significant Decrease (2024-07 to 2024-09)')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Tap Volume')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Service Number', bbox_to_anchor=(1, 1), loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c949e8",
   "metadata": {},
   "source": [
    "### 2a. Trend of Passenger Volumes by Bus Stops\n",
    "- Assumption: Passenger Volumes represented by Total Number of Tap Ins and Tap Outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c4024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'TOTAL_TAP_VOLUME' summing tap-in and tap-out volumes\n",
    "bus_stop_pv_jul['TOTAL_TAP_VOLUME'] = bus_stop_pv_jul['TOTAL_TAP_IN_VOLUME'] + bus_stop_pv_jul['TOTAL_TAP_OUT_VOLUME']\n",
    "bus_stop_pv_aug['TOTAL_TAP_VOLUME'] = bus_stop_pv_aug['TOTAL_TAP_IN_VOLUME'] + bus_stop_pv_aug['TOTAL_TAP_OUT_VOLUME']\n",
    "bus_stop_pv_sep['TOTAL_TAP_VOLUME'] = bus_stop_pv_sep['TOTAL_TAP_IN_VOLUME'] + bus_stop_pv_sep['TOTAL_TAP_OUT_VOLUME']\n",
    "\n",
    "# Group by PT_CODE and YEAR_MONTH to get total taps for each bus stop per month\n",
    "monthly_tap_jul = bus_stop_pv_jul.groupby(['PT_CODE', 'YEAR_MONTH'])[['TOTAL_TAP_VOLUME']].sum().reset_index()\n",
    "monthly_tap_aug = bus_stop_pv_aug.groupby(['PT_CODE', 'YEAR_MONTH'])[['TOTAL_TAP_VOLUME']].sum().reset_index()\n",
    "monthly_tap_sep = bus_stop_pv_sep.groupby(['PT_CODE', 'YEAR_MONTH'])[['TOTAL_TAP_VOLUME']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4725e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all three months' data\n",
    "all_months_taps = pd.concat([monthly_tap_jul, \n",
    "                             monthly_tap_aug,\n",
    "                             monthly_tap_sep])\n",
    "\n",
    "# Reset index after concatenation\n",
    "all_months_taps.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abf502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'PT_CODE' and 'BusStopCode' are of the same data type\n",
    "all_months_taps['PT_CODE'] = all_months_taps['PT_CODE'].astype(str)\n",
    "\n",
    "# Pivot the data to have 'ServiceNo' as rows and 'YEAR_MONTH' as columns\n",
    "tap_bus_stop_pivot = all_months_taps.pivot(index='PT_CODE', columns='YEAR_MONTH', values='TOTAL_TAP_VOLUME')\n",
    "\n",
    "# Preview the pivot table\n",
    "tap_bus_stop_pivot.head()\n",
    "\n",
    "# Assuming tap_in_pivot already has the data for '2024-07', '2024-08', and '2024-09'\n",
    "tap_bus_stop_pivot['Decreasing'] = (tap_bus_stop_pivot['2024-07'] > tap_bus_stop_pivot['2024-08']) & (tap_bus_stop_pivot['2024-08'] > tap_bus_stop_pivot['2024-09'])\n",
    "\n",
    "# Create a DataFrame for routes with decreasing tap-ins\n",
    "taps_bus_stop_df = tap_bus_stop_pivot[tap_bus_stop_pivot['Decreasing']].reset_index()\n",
    "taps_bus_stop_df.rename(columns={'YEAR_MONTH': 'Index'}, inplace=True)\n",
    "\n",
    "# Ensure that 'bus_routes_stops_cleaned' has unique 'BusStopCode'\n",
    "bus_routes_stops_cleaned = bus_routes_stops.drop_duplicates(subset=['BusStopCode'])\n",
    "\n",
    "# Merge to get the name and description for both the ORIGIN and DESTINATION in July\n",
    "decreasing_bus_stops_df = pd.merge(\n",
    "    taps_bus_stop_df, \n",
    "    bus_routes_stops_cleaned[['BusStopCode', 'RoadName', 'Description']],\n",
    "    left_on='PT_CODE', \n",
    "    right_on='BusStopCode', \n",
    "    how='left'\n",
    ").drop(columns=['BusStopCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c57aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the decrease from '2024-07' to '2024-09'\n",
    "decreasing_bus_stops_df['Decrease'] = decreasing_bus_stops_df['2024-07'] - decreasing_bus_stops_df['2024-09']\n",
    "\n",
    "# Sort the DataFrame by 'Decrease' in descending order\n",
    "decreasing_bus_stops_df_sorted = decreasing_bus_stops_df.sort_values(by='Decrease', ascending=False)\n",
    "decreasing_bus_stops_df_sorted.to_csv('../datasets/pv_eda/bus_stops_w_decreasing_pv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db750bf",
   "metadata": {},
   "source": [
    "### 2b. Normalise Passenger Volumes of Bus Stops by Unique Number of Bus Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74ac1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'bus_stop_code' and count the unique 'bus_service' for each stop\n",
    "bus_service_count = bus_routes_df.groupby('BusStopCode')['ServiceNo'].nunique().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "bus_service_count.columns = ['BusStopCode', 'TotalBusService']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cca68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the dataset\n",
    "normalised_bus_stops_df = pd.merge(decreasing_bus_stops_df, bus_service_count, \n",
    "                                   left_on = \"PT_CODE\", right_on = \"BusStopCode\",\n",
    "                                   how = \"left\").drop(columns=['BusStopCode'])\n",
    "normalised_bus_stops_df['Normalised'] = normalised_bus_stops_df['Decrease'] / normalised_bus_stops_df['TotalBusService']\n",
    "\n",
    "# Sort the DataFrame by 'Normalised' in descending order\n",
    "decreasing_normalised_bus_stops_df_sorted = normalised_bus_stops_df.sort_values(by='Normalised', ascending=False)\n",
    "decreasing_normalised_bus_stops_df_sorted.to_csv('../datasets/pv_eda/bus_stops_w_normalised_pv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33882d42",
   "metadata": {},
   "source": [
    "### 3. Average (Mean and Median) Monthly Bus Servicing the Same Origin and Destination Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ef47d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert both 'ORIGIN_PT_CODE' and 'DESTINATION_PT_CODE' columns to string for July\n",
    "bus_od_jul[['ORIGIN_PT_CODE', 'DESTINATION_PT_CODE']] = bus_od_jul[['ORIGIN_PT_CODE', 'DESTINATION_PT_CODE']].astype(str)\n",
    "bus_od_aug[['ORIGIN_PT_CODE', 'DESTINATION_PT_CODE']] = bus_od_aug[['ORIGIN_PT_CODE', 'DESTINATION_PT_CODE']].astype(str)\n",
    "bus_od_sep[['ORIGIN_PT_CODE', 'DESTINATION_PT_CODE']] = bus_od_sep[['ORIGIN_PT_CODE', 'DESTINATION_PT_CODE']].astype(str)\n",
    "\n",
    "# Group by 'YEAR_MONTH', 'ORIGIN_PT_CODE' and 'DESTINATION_PT_CODE'\n",
    "grouped_trips_jul = bus_od_jul.groupby(['YEAR_MONTH', 'ORIGIN_PT_CODE', 'DESTINATION_PT_CODE'])[['TOTAL_TRIPS']].sum().reset_index()\n",
    "grouped_trips_aug = bus_od_aug.groupby(['YEAR_MONTH', 'ORIGIN_PT_CODE', 'DESTINATION_PT_CODE'])[['TOTAL_TRIPS']].sum().reset_index()\n",
    "grouped_trips_sep = bus_od_sep.groupby(['YEAR_MONTH', 'ORIGIN_PT_CODE', 'DESTINATION_PT_CODE'])[['TOTAL_TRIPS']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1e8cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that 'bus_routes_stops_cleaned' has unique 'BusStopCode'\n",
    "bus_routes_stops_cleaned = bus_routes_stops.drop_duplicates(subset=['BusStopCode'])\n",
    "\n",
    "# Merge to get the name and description for both the ORIGIN and DESTINATION in July\n",
    "route_trips_jul = pd.merge(\n",
    "    grouped_trips_jul, \n",
    "    bus_routes_stops_cleaned[['BusStopCode', 'Description']].rename(columns={'Description': 'ORIGIN_DESCRIPTION'}),\n",
    "    left_on='ORIGIN_PT_CODE', \n",
    "    right_on='BusStopCode', \n",
    "    how='left'\n",
    ").drop(columns=['BusStopCode'])\n",
    "\n",
    "route_trips_jul = pd.merge(\n",
    "    route_trips_jul, \n",
    "    bus_routes_stops_cleaned[['BusStopCode', 'Description']].rename(columns={'Description': 'DESTINATION_DESCRIPTION'}),\n",
    "    left_on='DESTINATION_PT_CODE', \n",
    "    right_on='BusStopCode', \n",
    "    how='left'\n",
    ").drop(columns=['BusStopCode'])\n",
    "\n",
    "# Merge to get the name and description for both the ORIGIN and DESTINATION in July\n",
    "route_trips_aug = pd.merge(\n",
    "    grouped_trips_aug, \n",
    "    bus_routes_stops_cleaned[['BusStopCode', 'Description']].rename(columns={'Description': 'ORIGIN_DESCRIPTION'}),\n",
    "    left_on='ORIGIN_PT_CODE', \n",
    "    right_on='BusStopCode', \n",
    "    how='left'\n",
    ").drop(columns=['BusStopCode'])\n",
    "\n",
    "route_trips_aug = pd.merge(\n",
    "    route_trips_aug, \n",
    "    bus_routes_stops_cleaned[['BusStopCode', 'Description']].rename(columns={'Description': 'DESTINATION_DESCRIPTION'}),\n",
    "    left_on='DESTINATION_PT_CODE', \n",
    "    right_on='BusStopCode', \n",
    "    how='left'\n",
    ").drop(columns=['BusStopCode'])\n",
    "\n",
    "# Merge to get the name and description for both the ORIGIN and DESTINATION in July\n",
    "route_trips_sep = pd.merge(\n",
    "    grouped_trips_sep, \n",
    "    bus_routes_stops_cleaned[['BusStopCode', 'Description']].rename(columns={'Description': 'ORIGIN_DESCRIPTION'}),\n",
    "    left_on='ORIGIN_PT_CODE', \n",
    "    right_on='BusStopCode', \n",
    "    how='left'\n",
    ").drop(columns=['BusStopCode'])\n",
    "\n",
    "route_trips_sep = pd.merge(\n",
    "    route_trips_sep, \n",
    "    bus_routes_stops_cleaned[['BusStopCode', 'Description']].rename(columns={'Description': 'DESTINATION_DESCRIPTION'}),\n",
    "    left_on='DESTINATION_PT_CODE', \n",
    "    right_on='BusStopCode', \n",
    "    how='left'\n",
    ").drop(columns=['BusStopCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28082d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all three months' data\n",
    "all_months_trips = pd.concat([route_trips_jul, \n",
    "                             route_trips_aug,\n",
    "                             route_trips_sep])\n",
    "\n",
    "# Reset index after concatenation\n",
    "all_months_trips.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93016960",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_mean_total_trips = all_months_trips.groupby(['ORIGIN_PT_CODE', \n",
    "                                                'DESTINATION_PT_CODE', \n",
    "                                                'ORIGIN_DESCRIPTION', \n",
    "                                                'DESTINATION_DESCRIPTION'])[['TOTAL_TRIPS']].mean().reset_index()\n",
    "\n",
    "# Sort the DataFrame by 'TOTAL_TRIPS' in descending order\n",
    "mean_trips_sorted = monthly_mean_total_trips.sort_values(by='TOTAL_TRIPS', ascending=False)\n",
    "mean_trips_sorted.to_csv('../datasets/pv_eda/mean_trips.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e002ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_median_total_trips = all_months_trips.groupby(['ORIGIN_PT_CODE', \n",
    "                                                'DESTINATION_PT_CODE', \n",
    "                                                'ORIGIN_DESCRIPTION', \n",
    "                                                'DESTINATION_DESCRIPTION'])[['TOTAL_TRIPS']].median().reset_index()\n",
    "\n",
    "# Sort the DataFrame by 'TOTAL_TRIPS' in descending order\n",
    "median_trips_sorted = monthly_median_total_trips.sort_values(by='TOTAL_TRIPS', ascending=False)\n",
    "median_trips_sorted.to_csv('../datasets/pv_eda/median_trips.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a09de",
   "metadata": {},
   "source": [
    "## Summary\n",
    "1. Bus stops and services that saw a significant decrease are those that serve higher educational institutions (e.g. Polytechnics, ITEs) -- July to September coincide with term breaks\n",
    "2. Top bus services based on their monthly number of trips are those that serve short distances "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a0dd17",
   "metadata": {},
   "source": [
    "## EDA of Bus Routes and Services along Interchanges and Stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d30296",
   "metadata": {},
   "source": [
    "### 4. Total Number of Interchanges and Stations each Bus Service serves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd23f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_bus_stops = bus_stops_df[bus_stops_df['Description'].str.contains(r'\\b(Int|Stn)(\\b|[\\s/])', case=False, na=False)]\n",
    "filtered_bus_stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaddb698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the filtered bus stops with the bus routes dataframe\n",
    "merged_df = pd.merge(bus_routes_df, filtered_bus_stops, on='BusStopCode', how='inner')\n",
    "\n",
    "# Group by the service number and count the bus stops\n",
    "bus_service_stop_counts = merged_df.groupby('ServiceNo')['BusStopCode'].nunique().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "bus_service_stop_counts.columns = ['ServiceNo', 'CountOfStopsWithIntOrStn']\n",
    "\n",
    "# Sort the DataFrame by 'CountOfStopsWithIntOrStn' in descending order\n",
    "int_stn_bus_service_sorted = bus_service_stop_counts.sort_values(by='CountOfStopsWithIntOrStn', ascending=False)\n",
    "int_stn_bus_service_sorted.to_csv('../datasets/pv_eda/int_stn_bus_service.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d097e7",
   "metadata": {},
   "source": [
    "### 5a. Trend of Passenger Volume at Interchanges and Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1d8f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_stn_pv_sorted = decreasing_bus_stops_df_sorted[decreasing_bus_stops_df_sorted['Description'].str.contains(r'\\b(Int|Stn)(\\b|[\\s/])', case=False, na=False)]\n",
    "int_stn_pv_sorted.to_csv('../datasets/pv_eda/int_stn_pv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03adae5e",
   "metadata": {},
   "source": [
    "### 5b. Normalise Passenger Volume at Interchanges and Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b4b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_stn_pv_normalise_sorted = decreasing_normalised_bus_stops_df_sorted[decreasing_normalised_bus_stops_df_sorted['Description'].str.contains(r'Int|Stn', case=False, na=False)]\n",
    "int_stn_pv_normalise_sorted = decreasing_normalised_bus_stops_df_sorted[\n",
    "    decreasing_normalised_bus_stops_df_sorted['Description'].str.contains(\n",
    "        r'\\b(Int|Stn)(\\b|[\\s/])', case=False, na=False\n",
    "    )\n",
    "]\n",
    "\n",
    "int_stn_pv_softmax = int_stn_pv_normalise_sorted.copy()\n",
    "\n",
    "# Min-max scale Normalised column to range between 0 and 10\n",
    "scaler = MinMaxScaler(feature_range=(0, 10))\n",
    "int_stn_pv_softmax['Scaled_Normalised'] = scaler.fit_transform(int_stn_pv_softmax[['Normalised']])\n",
    "\n",
    "# Apply softmax on the scaled values\n",
    "max_scaled = int_stn_pv_softmax['Scaled_Normalised'].max()\n",
    "int_stn_pv_softmax['Softmax'] = np.exp(int_stn_pv_softmax['Scaled_Normalised'] - max_scaled) / np.sum(np.exp(int_stn_pv_softmax['Scaled_Normalised'] - max_scaled))\n",
    "\n",
    "int_stn_pv_softmax.to_csv('../datasets/pv_eda/int_stn_normalised_pv.csv', index=False)\n",
    "int_stn_pv_softmax[['PT_CODE', 'Normalised', 'Scaled_Normalised', 'Softmax']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2525ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles_to_test = [0.7, 0.8, 0.85, 0.9]\n",
    "results = {}\n",
    "\n",
    "for p in percentiles_to_test:\n",
    "    threshold_value = int_stn_pv_softmax['Softmax'].quantile(p)\n",
    "    filtered_threshold = int_stn_pv_softmax[int_stn_pv_softmax['Softmax'] > threshold_value]\n",
    "    results[p] = len(filtered_threshold)  # or any other metric of interest\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(list(results.items()), columns=['Percentile', 'Count'])\n",
    "print(results_df)\n",
    "\n",
    "plt.bar(results_df['Percentile'].astype(str), results_df['Count'])\n",
    "plt.xlabel('Percentile Threshold')\n",
    "plt.ylabel('Number of Routes Filtered')\n",
    "plt.title('Impact of Different Percentile Thresholds on Route Filtering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092fe4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold at the 80th percentile of the Softmax values\n",
    "threshold_value = int_stn_pv_softmax['Softmax'].quantile(0.8)\n",
    "\n",
    "# Filter for routes with Softmax values above this threshold\n",
    "filtered_threshold = int_stn_pv_softmax[int_stn_pv_softmax['Softmax'] > threshold_value]\n",
    "filtered_threshold = filtered_threshold['PT_CODE']\n",
    "\n",
    "# Merge the filtered bus stops with the bus routes dataframe\n",
    "merged_threshold_df = pd.merge(bus_routes_df, filtered_threshold, \n",
    "                               left_on='BusStopCode', right_on='PT_CODE', \n",
    "                               how='inner').drop(columns=['PT_CODE'])\n",
    "\n",
    "# Group by the service number and count the bus stops\n",
    "threshold_stop_counts = merged_threshold_df.groupby('ServiceNo')['BusStopCode'].nunique().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "threshold_stop_counts.columns = ['ServiceNo', 'IntStnLargeDecrease']\n",
    "\n",
    "# Sort the DataFrame by 'IntStnLargeDecrease' in descending order\n",
    "threshold_bus_service_sorted = threshold_stop_counts.sort_values(by='IntStnLargeDecrease', ascending=False)\n",
    "threshold_bus_service_sorted.to_csv('../datasets/pv_eda/threshold_int_stn_bus.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e2e31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select services that serve at least 3 stations or interchanges with a large decrease\n",
    "more_than_3_stops = threshold_bus_service_sorted[threshold_bus_service_sorted['IntStnLargeDecrease'] > 3]\n",
    "\n",
    "# Plot graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(more_than_3_stops['ServiceNo'], \n",
    "         more_than_3_stops['IntStnLargeDecrease'], \n",
    "         color='purple')\n",
    "plt.xlabel('Count of Stops with Large Decrease in Passenger Volume')\n",
    "plt.ylabel('Bus Service Number')\n",
    "plt.title('Count of Bus Stops with Large Decrease in Passenger Volume by Bus Service')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bcd73f",
   "metadata": {},
   "source": [
    "## EDA of Train Routes and Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c94e32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
