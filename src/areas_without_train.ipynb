{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time as time_module \n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import polyline\n",
    "from shapely.geometry import LineString, MultiLineString\n",
    "from shapely.ops import linemerge\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from geopy.distance import geodesic\n",
    "from shapely.ops import nearest_points\n",
    "import folium\n",
    "from folium import Element\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "os.environ['OGR_GEOMETRY_ACCEPT_UNCLOSED_RING'] = 'NO'\n",
    "\n",
    "# Retrieving api key\n",
    "load_dotenv(\"../key.env\")\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "TOKEN = os.getenv('ONEMAPTOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "geospatial_train_path = \"../datasets/geospatial_layer/TrainStation_Jul2024/RapidTransitSystemStation.shp\"\n",
    "train_stations = pd.read_excel(\"../datasets/Train_Stations.xls\")\n",
    "geospatial_train_gdf = gpd.read_file(geospatial_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run get_bus_info_function.ipynb\n",
    "bus_services_df = get_bus_info(\"https://datamall2.mytransport.sg/ltaodataservice/BusServices\", api_key)\n",
    "bus_routes_df = get_bus_info(\"https://datamall2.mytransport.sg/ltaodataservice/BusRoutes\", api_key)\n",
    "bus_stops_df = get_bus_info(\"https://datamall2.mytransport.sg/ltaodataservice/BusStops\", api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_routes_gdf = gpd.read_file('../datasets/filtered_bus_routes.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_routes_stops = pd.merge(bus_routes_df, bus_stops_df, on = \"BusStopCode\", how = 'left')\n",
    "bus_routes_stops = bus_routes_stops.merge(\n",
    "    bus_services_df[['ServiceNo', 'Category']],  # Select only the columns needed for merging\n",
    "    on='ServiceNo',  # Merge on BusStopCode\n",
    "    how='left'  # Use 'left' join to keep all rows from bus_routes_stops\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates and assign it back to the original DataFrame\n",
    "bus_routes_stops = bus_routes_stops.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Filter the DataFrame for rows with 'Category' equal to 'TRUNK'\n",
    "bus_routes_stops = bus_routes_stops[bus_routes_stops['Category'] == 'TRUNK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Union the geometries for the same station\n",
    "unioned_gdf = geospatial_train_gdf.dissolve(by='STN_NAM_DE',aggfunc='first')\n",
    "\n",
    "# Step 2: Calculate the centroid of the unioned polygon\n",
    "unioned_gdf['centroid'] = unioned_gdf.centroid\n",
    "unioned_gdf['geometry'] = unioned_gdf['centroid']\n",
    "\n",
    "# Reset index to clean up\n",
    "unioned_gdf.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Station_Code    MRT_Station           MRT_Line TYP_CD_DES  \\\n",
      "0          NS1    Jurong East  North-South Line         MRT   \n",
      "1          NS2    Bukit Batok  North-South Line         MRT   \n",
      "2          NS3   Bukit Gombak  North-South Line         MRT   \n",
      "3          NS4  Choa Chu Kang  North-South Line         MRT   \n",
      "4          NS5        Yew Tee  North-South Line         MRT   \n",
      "\n",
      "                      geometry  \n",
      "0  POINT (17866.487 35045.184)  \n",
      "1  POINT (18676.448 36790.872)  \n",
      "2  POINT (18940.178 37860.706)  \n",
      "3  POINT (18101.056 40790.989)  \n",
      "4  POINT (18438.643 42159.628)  \n"
     ]
    }
   ],
   "source": [
    "# Function to normalize station names in train_stations_df\n",
    "def normalize_station_name(name):\n",
    "    return name.strip().upper()  # Ensure names are uppercase for consistent merging\n",
    "\n",
    "# Apply normalization function to train_stations_df\n",
    "train_stations['Normalized_Station'] = train_stations['MRT_Station'].apply(normalize_station_name)\n",
    "\n",
    "# Create a column to append \" MRT STATION\" or \" LRT STATION\" based on the MRT_Line\n",
    "train_stations['Station_MRT_LRT'] = train_stations.apply(\n",
    "    lambda row: f\"{row['Normalized_Station']} MRT STATION\" if \"LRT\" not in row['MRT_Line'] else f\"{row['Normalized_Station']} LRT STATION\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Apply normalization to geospatial_train_df\n",
    "# Strip ' MRT STATION' and ' LRT STATION' and normalize to uppercase\n",
    "unioned_gdf['Normalized_Station'] = unioned_gdf['STN_NAM_DE'].str.strip().str.upper()\n",
    "\n",
    "# Perform the merge on 'Station_MRT_LRT' from train_stations and 'Normalized_Station' from unioned_gdf\n",
    "merged_train_stations = train_stations.merge(\n",
    "    unioned_gdf,\n",
    "    how='left',\n",
    "    left_on='Station_MRT_LRT',\n",
    "    right_on='Normalized_Station'\n",
    ")\n",
    "\n",
    "# Keeping necessary columns\n",
    "columns_to_keep = ['Station_Code', 'MRT_Station', 'MRT_Line', 'TYP_CD_DES', 'geometry']\n",
    "merged_train_stations = merged_train_stations[columns_to_keep]\n",
    "\n",
    "# Check the resulting column names and sample data\n",
    "print(merged_train_stations.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Station_Code    MRT_Station           MRT_Line   Longitude  Latitude  \\\n",
      "0          NS1    Jurong East  North-South Line   103.742263  1.333209   \n",
      "1          NS2    Bukit Batok  North-South Line   103.749541  1.348997   \n",
      "2          NS3   Bukit Gombak  North-South Line   103.751910  1.358672   \n",
      "3          NS4  Choa Chu Kang  North-South Line   103.744369  1.385172   \n",
      "4          NS5        Yew Tee  North-South Line   103.747402  1.397550   \n",
      "\n",
      "  Train_Line  Station_No  \n",
      "0         NS           1  \n",
      "1         NS           2  \n",
      "2         NS           3  \n",
      "3         NS           4  \n",
      "4         NS           5  \n"
     ]
    }
   ],
   "source": [
    "#  Convert Pandas DataFrame to a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(merged_train_stations, geometry='geometry')\n",
    "\n",
    "#  Reproject the GeoDataFrame to EPSG:4326 (WGS 84 - latitude/longitude)\n",
    "gdf_4326 = gdf.to_crs(epsg=4326)\n",
    "\n",
    "# Extract Longitude and Latitude from the reprojected geometries\n",
    "gdf_4326['Longitude'] = gdf_4326.geometry.x\n",
    "gdf_4326['Latitude'] = gdf_4326.geometry.y\n",
    "\n",
    "#  Convert back to a Pandas DataFrame (if you don't need the geometry anymore)\n",
    "merged_train_stations = pd.DataFrame(gdf_4326)\n",
    "\n",
    "# Removing redundant columns\n",
    "columns_to_keep = ['Station_Code', 'MRT_Station', 'MRT_Line', 'Longitude', 'Latitude']\n",
    "merged_train_stations = merged_train_stations[columns_to_keep]\n",
    "merged_train_stations['Train_Line'] = merged_train_stations['Station_Code'].str.extract(r'([A-Za-z]+)')\n",
    "merged_train_stations['Station_No'] = merged_train_stations['Station_Code'].str.extract(r'(\\d+)').fillna(1).astype(int)\n",
    "print(merged_train_stations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_and_modify_station_code(df, original_code, new_codes):\n",
    "    \"\"\"\n",
    "    Duplicates a row based on the original station code and replaces it \n",
    "    with multiple new station codes.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The original dataframe.\n",
    "    original_code (str): The Station_Code to find and duplicate.\n",
    "    new_codes (list of str): The list of new Station_Codes to replace the original with.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated dataframe with the original code replaced by new codes.\n",
    "    \"\"\"\n",
    "    # Select the row with the specified original code\n",
    "    original_row = df[df['Station_Code'] == original_code]\n",
    "    \n",
    "    # Create modified copies of the row for each new code\n",
    "    new_rows = []\n",
    "    for code in new_codes:\n",
    "        new_row = original_row.copy()\n",
    "        new_row['Station_Code'] = code\n",
    "        new_rows.append(new_row)\n",
    "    \n",
    "    # Remove the original row and add the modified copies\n",
    "    df = df[df['Station_Code'] != original_code]\n",
    "    df = pd.concat([df] + new_rows, ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station_Code</th>\n",
       "      <th>MRT_Station</th>\n",
       "      <th>MRT_Line</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Train_Line</th>\n",
       "      <th>Station_No</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NS1</td>\n",
       "      <td>Jurong East</td>\n",
       "      <td>North-South Line</td>\n",
       "      <td>103.742263</td>\n",
       "      <td>1.333209</td>\n",
       "      <td>NS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NS2</td>\n",
       "      <td>Bukit Batok</td>\n",
       "      <td>North-South Line</td>\n",
       "      <td>103.749541</td>\n",
       "      <td>1.348997</td>\n",
       "      <td>NS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NS3</td>\n",
       "      <td>Bukit Gombak</td>\n",
       "      <td>North-South Line</td>\n",
       "      <td>103.751910</td>\n",
       "      <td>1.358672</td>\n",
       "      <td>NS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NS4</td>\n",
       "      <td>Choa Chu Kang</td>\n",
       "      <td>North-South Line</td>\n",
       "      <td>103.744369</td>\n",
       "      <td>1.385172</td>\n",
       "      <td>NS</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NS5</td>\n",
       "      <td>Yew Tee</td>\n",
       "      <td>North-South Line</td>\n",
       "      <td>103.747402</td>\n",
       "      <td>1.397550</td>\n",
       "      <td>NS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Station_Code    MRT_Station           MRT_Line   Longitude  Latitude  \\\n",
       "0          NS1    Jurong East  North-South Line   103.742263  1.333209   \n",
       "1          NS2    Bukit Batok  North-South Line   103.749541  1.348997   \n",
       "2          NS3   Bukit Gombak  North-South Line   103.751910  1.358672   \n",
       "3          NS4  Choa Chu Kang  North-South Line   103.744369  1.385172   \n",
       "4          NS5        Yew Tee  North-South Line   103.747402  1.397550   \n",
       "\n",
       "  Train_Line  Station_No  \n",
       "0         NS           1  \n",
       "1         NS           2  \n",
       "2         NS           3  \n",
       "3         NS           4  \n",
       "4         NS           5  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Union the geometries for the same station\n",
    "unioned_gdf = geospatial_train_gdf.dissolve(by='STN_NAM_DE',aggfunc='first')\n",
    "\n",
    "# Step 2: Calculate the centroid of the unioned polygon\n",
    "unioned_gdf['centroid'] = unioned_gdf.centroid\n",
    "\n",
    "# Optional Step: Replace geometry with centroid point\n",
    "unioned_gdf['geometry'] = unioned_gdf['centroid']\n",
    "\n",
    "# Reset index to clean up\n",
    "unioned_gdf.reset_index(inplace=True)\n",
    "\n",
    "# Function to normalize station names in train_stations_df\n",
    "def normalize_station_name(name):\n",
    "    return name.strip().upper()  # Ensure names are uppercase for consistent merging\n",
    "\n",
    "# Apply normalization function to train_stations_df\n",
    "train_stations['Normalized_Station'] = train_stations['MRT_Station'].apply(normalize_station_name)\n",
    "\n",
    "# Create a column to append \" MRT STATION\" or \" LRT STATION\" based on the MRT_Line\n",
    "train_stations['Station_MRT_LRT'] = train_stations.apply(\n",
    "    lambda row: f\"{row['Normalized_Station']} MRT STATION\" if \"LRT\" not in row['MRT_Line'] else f\"{row['Normalized_Station']} LRT STATION\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Apply normalization to geospatial_train_df\n",
    "# Strip ' MRT STATION' and ' LRT STATION' and normalize to uppercase\n",
    "unioned_gdf['Normalized_Station'] = unioned_gdf['STN_NAM_DE'].str.strip().str.upper()\n",
    "\n",
    "# Perform the merge on 'Station_MRT_LRT' from train_stations and 'Normalized_Station' from unioned_gdf\n",
    "merged_train_stations = train_stations.merge(\n",
    "    unioned_gdf,\n",
    "    how='left',\n",
    "    left_on='Station_MRT_LRT',\n",
    "    right_on='Normalized_Station'\n",
    ")\n",
    "\n",
    "merged_train_stations = merged_train_stations[['Station_Code', 'MRT_Station', 'MRT_Line', 'TYP_CD_DES', 'geometry']]\n",
    "\n",
    "#  Convert Pandas DataFrame to a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(merged_train_stations, geometry='geometry')\n",
    "\n",
    "#  Reproject the GeoDataFrame to EPSG:4326 (WGS 84 - latitude/longitude)\n",
    "gdf_4326 = gdf.to_crs(epsg=4326)\n",
    "\n",
    "# Extract Longitude and Latitude from the reprojected geometries\n",
    "gdf_4326['Longitude'] = gdf_4326.geometry.x\n",
    "gdf_4326['Latitude'] = gdf_4326.geometry.y\n",
    "\n",
    "#  Convert back to a Pandas DataFrame (if you don't need the geometry anymore)\n",
    "geospatial_train_station = pd.DataFrame(gdf_4326)\n",
    "\n",
    "geospatial_train_station = geospatial_train_station[['Station_Code', 'MRT_Station', 'MRT_Line', 'Longitude', 'Latitude']]\n",
    "\n",
    "# Duplicate the row with 'PTC' and replace it with 'PW0', PW8', 'PE0', 'PE8'\n",
    "geospatial_train_station = duplicate_and_modify_station_code(geospatial_train_station, 'PTC', ['PW0', 'PW8', 'PE0', 'PE8'])\n",
    "# Duplicate the row with 'STC' and replace it with 'SW0', 'SW9', 'SE0', 'SE6'\n",
    "geospatial_train_station = duplicate_and_modify_station_code(geospatial_train_station, 'STC', ['SW0', 'SW9', 'SE0', 'SE6'])\n",
    "# Duplicate the row with 'BP6' and replace it with 'BP6', 'BP14'\n",
    "geospatial_train_station = duplicate_and_modify_station_code(geospatial_train_station, 'BP6', ['BP6', 'BP14'])\n",
    "\n",
    "geospatial_train_station['Train_Line'] = geospatial_train_station['Station_Code'].str.extract(r'([A-Za-z]+)')\n",
    "geospatial_train_station['Station_No'] = geospatial_train_station['Station_Code'].str.extract(r'(\\d+)').fillna(1).astype(int)\n",
    "\n",
    "geospatial_train_station.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train_Line                                           geometry\n",
      "0         BP  LINESTRING (103.74455 1.38482, 103.74529 1.380...\n",
      "1         CC  LINESTRING (103.84572 1.29938, 103.85066 1.296...\n",
      "2         CE   LINESTRING (103.85908 1.28187, 103.85498 1.2757)\n",
      "3         CG  LINESTRING (103.96205 1.33497, 103.98837 1.35731)\n",
      "4         DT  LINESTRING (103.76157 1.37916, 103.7647 1.3693...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aiko\\AppData\\Local\\Temp\\ipykernel_38700\\3452923685.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_lines_gdf = train_stations_gdf.groupby('Train_Line').apply(\n"
     ]
    }
   ],
   "source": [
    "# Convert to GeoDataFrame\n",
    "train_stations_gdf = gpd.GeoDataFrame(\n",
    "    geospatial_train_station,\n",
    "    geometry=gpd.points_from_xy(geospatial_train_station.Longitude, geospatial_train_station.Latitude),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Step 2: Sort and group by train line to form continuous line segments for each line\n",
    "train_stations_gdf = train_stations_gdf.sort_values(by=['Train_Line', 'Station_No'])\n",
    "\n",
    "# Group by each train line to create LineString for each line\n",
    "train_lines_gdf = train_stations_gdf.groupby('Train_Line').apply(\n",
    "    lambda group: LineString(group.geometry.tolist()) if len(group) > 1 else None\n",
    ").reset_index(name='geometry')\n",
    "\n",
    "# Filter out rows where geometry is None (i.e., groups with less than 2 geometries)\n",
    "train_lines_gdf = train_lines_gdf[train_lines_gdf['geometry'].notna()]\n",
    "\n",
    "# Convert the result into a GeoDataFrame, which represents each train line as a LineString\n",
    "train_lines_gdf = gpd.GeoDataFrame(train_lines_gdf, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "# Display the first few rows to confirm\n",
    "print(train_lines_gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert bus stops (Pandas DataFrame) to GeoDataFrame with geometry points\n",
    "bus_routes_stops_gdf = gpd.GeoDataFrame(\n",
    "    bus_routes_stops,\n",
    "    geometry=gpd.points_from_xy(bus_routes_stops['Longitude'], bus_routes_stops['Latitude']),\n",
    "    crs=\"EPSG:4326\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aiko\\AppData\\Local\\Temp\\ipykernel_38700\\3228668025.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_lines_gdf = train_stations_gdf.groupby('Train_Line').apply(\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "DISTANCE_THRESHOLD = 500  # Distance in meters\n",
    "ANGLE_THRESHOLD = 50  # Maximum angle in degrees for coverage\n",
    "projected_crs = \"EPSG:3414\"  # Change this to an appropriate projected CRS for your area\n",
    "\n",
    "# Convert bus stops and train stations to GeoDataFrames with EPSG:4326\n",
    "bus_routes_stops_gdf = gpd.GeoDataFrame(\n",
    "    bus_routes_stops,\n",
    "    geometry=gpd.points_from_xy(bus_routes_stops['Longitude'], bus_routes_stops['Latitude']),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "train_stations_gdf = gpd.GeoDataFrame(\n",
    "    geospatial_train_station,\n",
    "    geometry=gpd.points_from_xy(geospatial_train_station.Longitude, geospatial_train_station.Latitude),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Convert to projected CRS for accurate distance calculations\n",
    "bus_routes_stops_gdf = bus_routes_stops_gdf.to_crs(projected_crs)\n",
    "train_stations_gdf = train_stations_gdf.to_crs(projected_crs)\n",
    "\n",
    "# Sort and group train stations to create continuous line segments for each train line\n",
    "train_stations_gdf = train_stations_gdf.sort_values(by=['Train_Line', 'Station_No'])\n",
    "train_lines_gdf = train_stations_gdf.groupby('Train_Line').apply(\n",
    "    lambda group: LineString(group.geometry.tolist()) if len(group) > 1 else None\n",
    ").reset_index(name='geometry')\n",
    "train_lines_gdf = train_lines_gdf[train_lines_gdf['geometry'].notna()]\n",
    "train_lines_gdf = gpd.GeoDataFrame(train_lines_gdf, geometry='geometry', crs=projected_crs)\n",
    "\n",
    "# Function to calculate the angle between two points\n",
    "def calculate_angle(bus_p1, bus_p2, train_p1, train_p2):\n",
    "    bus_dx = bus_p1.x - bus_p2.x\n",
    "    bus_dy = bus_p1.y - bus_p2.y\n",
    "    bus_norm = math.sqrt(bus_dy ** 2 + bus_dx ** 2)\n",
    "\n",
    "    train_dx = train_p1.x - train_p2.x\n",
    "    train_dy = train_p1.y - train_p2.y\n",
    "    train_norm = math.sqrt(train_dy ** 2 + train_dx ** 2)\n",
    "\n",
    "    if bus_norm == 0 or train_norm == 0:\n",
    "        return 180  # No angle if there is no valid segment\n",
    "\n",
    "    norm_dot_prod = (bus_dx * train_dx + bus_dy * train_dy) / (bus_norm * train_norm)\n",
    "    angle = np.degrees(np.arccos(norm_dot_prod))\n",
    "\n",
    "    return angle if angle <= 90 else 180 - angle\n",
    "\n",
    "# Function to find bus stops not covered by train stations and calculate a normalized score\n",
    "def find_bus_stops_not_covered_by_trains(bus_routes_stops_gdf, train_stations_gdf, distance_threshold, angle_threshold):\n",
    "    results = []\n",
    "    for service_no, service_data in bus_routes_stops_gdf.groupby('ServiceNo'):\n",
    "        total_stops = len(service_data)\n",
    "        uncovered_count = 0\n",
    "        for index, bus_stop in service_data.iterrows():\n",
    "            bus_stop_geom = bus_stop.geometry\n",
    "            nearby_train_stations = train_stations_gdf[train_stations_gdf.geometry.distance(bus_stop_geom) <= distance_threshold]\n",
    "            if nearby_train_stations.empty:\n",
    "                uncovered_count += 1\n",
    "            else:\n",
    "                for _, train_station in nearby_train_stations.iterrows():\n",
    "                    train_station_geom = train_station.geometry\n",
    "                    if index > 0 and index < total_stops - 1:\n",
    "                        prev_bus_stop = service_data.iloc[index - 1].geometry\n",
    "                        next_bus_stop = service_data.iloc[index + 1].geometry\n",
    "                        bus_angle = calculate_angle(prev_bus_stop, next_bus_stop, train_station_geom, bus_stop_geom)\n",
    "                        if bus_angle > angle_threshold:\n",
    "                            uncovered_count += 1\n",
    "        if total_stops > 0:\n",
    "            proportion_uncovered = uncovered_count / total_stops\n",
    "            score = proportion_uncovered\n",
    "        else:\n",
    "            weighted_score = 0\n",
    "        results.append({\n",
    "            'ServiceNo': service_no,\n",
    "            'TotalStops': total_stops,\n",
    "            'UncoveredStops': uncovered_count,\n",
    "            'Score': score\n",
    "        })\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values(by='Score', ascending=False)\n",
    "    return results_df\n",
    "\n",
    "# Run the function to find uncovered bus stops and their scores\n",
    "uncovered_bus_stops_df = find_bus_stops_not_covered_by_trains(bus_routes_stops_gdf, train_stations_gdf, DISTANCE_THRESHOLD, ANGLE_THRESHOLD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ServiceNo  TotalStops  UncoveredStops     Score\n",
      "241         6          30              28  0.933333\n",
      "389       98B          27              25  0.925926\n",
      "388       98A          11              10  0.909091\n",
      "44        127          22              20  0.909091\n",
      "340       927          33              30  0.909091\n",
      "255        68          42              38  0.904762\n",
      "127       17A          10               9  0.900000\n",
      "29       117A          10               9  0.900000\n",
      "331       89A          37              33  0.891892\n",
      "132      181M          18              16  0.888889\n",
      "262       70B          18              16  0.888889\n",
      "64       139A           9               8  0.888889\n",
      "131       181          18              16  0.888889\n",
      "210       405          35              31  0.885714\n",
      "377      975B          33              29  0.878788\n",
      "15       109A          15              13  0.866667\n",
      "257       68B           7               6  0.857143\n",
      "256       68A           7               6  0.857143\n",
      "158       199          27              23  0.851852\n",
      "112        17          62              52  0.838710\n"
     ]
    }
   ],
   "source": [
    "print(uncovered_bus_stops_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ServiceNo  TotalStops     Score\n",
      "241         6          30  0.933333\n",
      "44        127          22  0.909091\n",
      "340       927          33  0.909091\n",
      "255        68          42  0.904762\n",
      "131       181          18  0.888889\n",
      "210       405          35  0.885714\n",
      "158       199          27  0.851852\n",
      "112        17          62  0.838710\n",
      "265        72          89  0.831461\n",
      "194        35          35  0.828571\n",
      "397       992          29  0.827586\n",
      "180        29          54  0.814815\n",
      "381        98          69  0.811594\n",
      "133       182          58  0.810345\n",
      "337       925          78  0.807692\n",
      "144        19          56  0.803571\n",
      "7         103          85  0.800000\n",
      "0          10         148  0.797297\n",
      "135       183          58  0.793103\n",
      "163       201          38  0.789474\n"
     ]
    }
   ],
   "source": [
    "# Filter the final results to exclude ServiceNos with alphabetic characters\n",
    "filtered_final_results = uncovered_bus_stops_df[~uncovered_bus_stops_df['ServiceNo'].str.contains(r'[A-Za-z]')]\n",
    "\n",
    "# Display filtered results\n",
    "print(filtered_final_results[['ServiceNo', 'TotalStops','Score']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_final_results.to_csv('../datasets/areas_without_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Thresholds:\n",
      "Distance Threshold: 500 meters\n",
      "Angle Threshold: 50 degrees\n",
      "Best Score: 0.5344018248091917\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Constants for threshold ranges\n",
    "DISTANCE_THRESHOLD_RANGE = range(50, 501, 50)  # Distance from 50 to 500 meters\n",
    "ANGLE_THRESHOLD_RANGE = range(0, 91, 5)  # Angle from 0 to 90 degrees in increments of 5\n",
    "NUM_SAMPLES = 10  # Number of random samples to test for thresholds\n",
    "\n",
    "# Randomly sample thresholds\n",
    "sampled_thresholds = [\n",
    "    (random.choice(DISTANCE_THRESHOLD_RANGE), random.choice(ANGLE_THRESHOLD_RANGE))\n",
    "    for _ in range(NUM_SAMPLES)\n",
    "]\n",
    "\n",
    "# Define the function to evaluate thresholds\n",
    "def evaluate_thresholds(distance_threshold, angle_threshold):\n",
    "    uncovered_bus_stops_df = find_bus_stops_not_covered_by_trains(bus_routes_stops_gdf, train_stations_gdf, distance_threshold, angle_threshold)\n",
    "    best_score = uncovered_bus_stops_df['Score'].mean()  # Adjust based on your criteria\n",
    "    return distance_threshold, angle_threshold, best_score\n",
    "\n",
    "# Use parallel processing to evaluate thresholds\n",
    "results = Parallel(n_jobs=-1)(delayed(evaluate_thresholds)(dt, at) for dt, at in sampled_thresholds)\n",
    "\n",
    "# Find the best combination from the results\n",
    "best_combination = min(results, key=lambda x: x[2])  # Minimize the score\n",
    "print(\"Optimal Thresholds:\")\n",
    "print(f\"Distance Threshold: {best_combination[0]} meters\")\n",
    "print(f\"Angle Threshold: {best_combination[1]} degrees\")\n",
    "print(f\"Best Score: {best_combination[2]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
