{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time as time_module \n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "os.environ['OGR_GEOMETRY_ACCEPT_UNCLOSED_RING'] = 'NO'\n",
    "\n",
    "# Retrieving api key\n",
    "load_dotenv(\"../key.env\")\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "TOKEN = os.getenv('ONEMAPTOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "geospatial_train_path = \"../datasets/geospatial_layer/TrainStation_Jul2024/RapidTransitSystemStation.shp\"\n",
    "train_stations = pd.read_excel(\"../datasets/Train_Stations.xls\")\n",
    "geospatial_train_gdf = gpd.read_file(geospatial_train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data-Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Union the geometries for the same station\n",
    "unioned_gdf = geospatial_train_gdf.dissolve(by='STN_NAM_DE',aggfunc='first')\n",
    "\n",
    "# Step 2: Calculate the centroid of the unioned polygon\n",
    "unioned_gdf['centroid'] = unioned_gdf.centroid\n",
    "\n",
    "# Optional Step: Replace geometry with centroid point\n",
    "unioned_gdf['geometry'] = unioned_gdf['centroid']\n",
    "\n",
    "# Reset index to clean up\n",
    "unioned_gdf.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize station names in train_stations_df\n",
    "def normalize_station_name(name):\n",
    "    return name.strip().upper()  # Ensure names are uppercase for consistent merging\n",
    "\n",
    "# Apply normalization function to train_stations_df\n",
    "train_stations['Normalized_Station'] = train_stations['MRT_Station'].apply(normalize_station_name)\n",
    "\n",
    "# Create a column to append \" MRT STATION\" or \" LRT STATION\" based on the MRT_Line\n",
    "train_stations['Station_MRT_LRT'] = train_stations.apply(\n",
    "    lambda row: f\"{row['Normalized_Station']} MRT STATION\" if \"LRT\" not in row['MRT_Line'] else f\"{row['Normalized_Station']} LRT STATION\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Apply normalization to geospatial_train_df\n",
    "# Strip ' MRT STATION' and ' LRT STATION' and normalize to uppercase\n",
    "unioned_gdf['Normalized_Station'] = unioned_gdf['STN_NAM_DE'].str.strip().str.upper()\n",
    "\n",
    "# Perform the merge on 'Station_MRT_LRT' from train_stations and 'Normalized_Station' from unioned_gdf\n",
    "merged_train_stations = train_stations.merge(\n",
    "    unioned_gdf,\n",
    "    how='left',\n",
    "    left_on='Station_MRT_LRT',\n",
    "    right_on='Normalized_Station'\n",
    ")\n",
    "\n",
    "# Keeping necessary columns\n",
    "columns_to_keep = ['Station_Code', 'MRT_Station', 'MRT_Line', 'TYP_CD_DES', 'geometry']\n",
    "merged_train_stations = merged_train_stations[columns_to_keep]\n",
    "\n",
    "# Check the resulting column names and sample data\n",
    "print(merged_train_stations.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Convert Pandas DataFrame to a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(merged_train_stations, geometry='geometry')\n",
    "\n",
    "#  Reproject the GeoDataFrame to EPSG:4326 (WGS 84 - latitude/longitude)\n",
    "gdf_4326 = gdf.to_crs(epsg=4326)\n",
    "\n",
    "# Extract Longitude and Latitude from the reprojected geometries\n",
    "gdf_4326['Longitude'] = gdf_4326.geometry.x\n",
    "gdf_4326['Latitude'] = gdf_4326.geometry.y\n",
    "\n",
    "#  Convert back to a Pandas DataFrame (if you don't need the geometry anymore)\n",
    "merged_train_stations = pd.DataFrame(gdf_4326)\n",
    "\n",
    "# Removing redundant columns\n",
    "columns_to_keep = ['Station_Code', 'MRT_Station', 'MRT_Line', 'Longitude', 'Latitude']\n",
    "merged_train_stations = merged_train_stations[columns_to_keep]\n",
    "print(merged_train_stations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fetching MRT Routes from OneMapSg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch rail route from OneMap API\n",
    "def fetch_route(start, end, date, route_time, mode='RAIL'):\n",
    "    url = 'https://www.onemap.gov.sg/api/public/routingsvc/route'\n",
    "    params = {\n",
    "        'start': start,\n",
    "        'end': end,\n",
    "        'routeType': 'pt',\n",
    "        'date': date,\n",
    "        'time': route_time,\n",
    "        'mode': mode,\n",
    "        'maxWalkDistance': 1000,\n",
    "        'numItineraries': 3\n",
    "    }\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {TOKEN}'\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching route from {start} to {end}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Main function to iterate through MRT stations dataframe and fetch the route\n",
    "def main(mrt_stations_df):\n",
    "    # Iterate through each station to create routes between consecutive stations\n",
    "    for i in range(len(mrt_stations_df) - 1):\n",
    "        start_station = mrt_stations_df.iloc[i]\n",
    "        end_station = mrt_stations_df.iloc[i + 1]\n",
    "\n",
    "        start = f\"{start_station['Latitude']},{start_station['Longitude']}\"\n",
    "        end = f\"{end_station['Latitude']},{end_station['Longitude']}\"\n",
    "\n",
    "        date = '10-29-2024'  # Replace with actual date\n",
    "        route_time = '12:00:00'  # Set initial time to 12:00 PM\n",
    "\n",
    "        # Attempt fetching the route, with retries if needed\n",
    "        for _ in range(5):  # Attempt up to 5 times with increasing time intervals\n",
    "            data = fetch_route(start, end, date, route_time)\n",
    "            if data is not None:\n",
    "                break\n",
    "            # Increment the time by 30 minutes for the next attempt\n",
    "            hour, minute, second = map(int, route_time.split(':'))\n",
    "            minute += 15\n",
    "            if minute >= 60:\n",
    "                minute -= 60\n",
    "                hour += 1\n",
    "            route_time = f\"{hour:02d}:{minute:02d}:{second:02d}\"\n",
    "\n",
    "        # Save route to file if route data is fetched\n",
    "        if data is not None:\n",
    "            file_path = f\"../datasets/routes/onemapsg_mrt/{start_station['Station_Code']}.json\"\n",
    "            with open(file_path, 'w') as f:\n",
    "                json.dump(data, f, indent=2)\n",
    "            print(f\"Generated {file_path}\")\n",
    "\n",
    "            # Delay to avoid API rate limiting\n",
    "            time_module.sleep(1)\n",
    "        else:\n",
    "            print(f\"Failed to fetch route between {start_station['MRT_Station']} and {end_station['MRT_Station']}\")\n",
    "\n",
    "# Run the main function\n",
    "main(merged_train_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching Routes of TEL4 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSA4264",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
